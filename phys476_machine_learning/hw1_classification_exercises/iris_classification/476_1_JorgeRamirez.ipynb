{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Activation, Dropout\n",
    "from keras.callbacks import History\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import plot_model\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\"\"\"\n",
    "This jupyter notebook is based on using machine learning \n",
    "to classify species of flowers from a canonical data set\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "this cell is for importing the data, assumed to be in the same directory as .py file\n",
    "\n",
    "   1. sepal length in cm\n",
    "   2. sepal width in cm\n",
    "   3. petal length in cm\n",
    "   4. petal width in cm\n",
    "   5. class: \n",
    "      -- Iris Setosa\n",
    "      -- Iris Versicolour\n",
    "      -- Iris Virginica\n",
    "\"\"\"\n",
    "\n",
    "  # load .data file into a pandas dataframe\n",
    "filepath = \"bezdekIris.data\"\n",
    "data = pd.read_csv(filepath, header=None, names=['sepal length','sepal width', 'petal length',\n",
    "                                                        'petal width','class'])\n",
    "\n",
    "  # one hot encode the classifications\n",
    "data = pd.concat([pd.get_dummies(data['class'], prefix='class'), data], axis=1)  \n",
    "del data['class']  # remove column with strings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This cell is for creating training and testing datasets\n",
    "\"\"\"\n",
    "\n",
    "  # first take a random 90% of the data, use it as our training data\n",
    "train_data = data.sample(frac = 9/10, axis = 0)\n",
    "\n",
    "  # take everything else to be our testing data\n",
    "test_data = data.drop(train_data.index)\n",
    "  \n",
    "    \n",
    "\"\"\"\n",
    "train_in will be the input data we use to train our network\n",
    "train_out will be used as the answer key for the training done on train_in\n",
    "\"\"\"\n",
    "  # save columns that have the answer into train_out\n",
    "train_out = train_data[['class_Iris-setosa', 'class_Iris-versicolor', 'class_Iris-virginica']].values  \n",
    "\n",
    "  # now delete the columns we just saved and save the rest as input\n",
    "del train_data['class_Iris-versicolor']\n",
    "del train_data['class_Iris-virginica']\n",
    "del train_data['class_Iris-setosa']\n",
    "train_in = train_data.values\n",
    "\n",
    "\n",
    "\"\"\" \n",
    "test_in will be the input parameters for seeing if our network works\n",
    "test_out will be the answer key for test_in\n",
    "\"\"\"\n",
    "  # save columns that have the answer into test_out\n",
    "test_out = test_data[['class_Iris-setosa', 'class_Iris-versicolor', 'class_Iris-virginica']].values\n",
    "\n",
    "  # now delete the columns we just saved into train_out and save the rest as input\n",
    "del test_data['class_Iris-versicolor']\n",
    "del test_data['class_Iris-virginica']\n",
    "del test_data['class_Iris-setosa']\n",
    "test_in = test_data.values\n",
    "\n",
    "\n",
    "  # clean up and delete unused arrays\n",
    "del train_data\n",
    "del test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "making a net with several hidden layers and some dropout sprinkled in because that's cool\n",
    "\"\"\"\n",
    "\n",
    "  # initialize a linear network structure\n",
    "model = Sequential()\n",
    "\n",
    "  # add some layers\n",
    "model.add(Dense(units=64, activation='relu', input_dim=4))\n",
    "\n",
    "model.add(Dense(units=32, activation='relu'))\n",
    "\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Dense(units=16, activation='relu'))\n",
    "\n",
    "model.add(Dense(units=8, activation='relu'))\n",
    "\n",
    "model.add(Dense(units=3, activation='softmax'))\n",
    "\n",
    "\n",
    "  # configure learning process\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='Adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "  # train model for a few epochs. x is the input, y is the target (TRAINING) data\n",
    "history = model.fit(x=train_in, y=train_out, epochs=15, verbose=2, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate performance, x is input and y is target (TESTING) data\n",
    "    \n",
    "loss_and_metrics_1 = model.evaluate(x=test_in, y=test_out, verbose=1)\n",
    "\n",
    "print(\"\\n\\nResult of testing on test data:\")\n",
    "print(model.metrics_names)\n",
    "print(loss_and_metrics_1)\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['accuracy'], label=\"Accuracy\")\n",
    "\n",
    "plt.title('History of Net Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
